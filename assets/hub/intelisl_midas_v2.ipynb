{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intelisl_midas_v2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "947d38503d8b42b0bce66b5f009bb1e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f9cfb46e074e44cf87cc84e59c03b5c8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_86711289496646169611e33496d984be",
              "IPY_MODEL_08332669b3624318acd84cf1e6e31269",
              "IPY_MODEL_7001155c7eb6403d86288fbbd6524466"
            ]
          }
        },
        "f9cfb46e074e44cf87cc84e59c03b5c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "86711289496646169611e33496d984be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0f3249c81aed41af965eede09697119c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c0b8e5014654f0f8b4ac1eeb0a79898"
          }
        },
        "08332669b3624318acd84cf1e6e31269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_29b943ee38a345dd8b7e5498c097d1da",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1376378527,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1376378527,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_43bc410a74d64fc99425f01aab3dc551"
          }
        },
        "7001155c7eb6403d86288fbbd6524466": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c4821fc1537c4fafad67ad9c6821b0f8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.28G/1.28G [00:19&lt;00:00, 79.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d901f7b7c3d4f3a84115f1d2b92812f"
          }
        },
        "0f3249c81aed41af965eede09697119c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c0b8e5014654f0f8b4ac1eeb0a79898": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29b943ee38a345dd8b7e5498c097d1da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "43bc410a74d64fc99425f01aab3dc551": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c4821fc1537c4fafad67ad9c6821b0f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d901f7b7c3d4f3a84115f1d2b92812f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pdanahy/ML-public/blob/main/assets/hub/intelisl_midas_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmQFjLn6bhMY"
      },
      "source": [
        "### This notebook is optionally accelerated with a GPU runtime.\n",
        "### If you would like to use this acceleration, please select the menu option \"Runtime\" -> \"Change runtime type\", select \"Hardware Accelerator\" -> \"GPU\" and click \"SAVE\"\n",
        "\n",
        "----------------------------------------------------------------------\n",
        "\n",
        "# MiDaS\n",
        "\n",
        "*Author: Intel ISL*\n",
        "\n",
        "**MiDaS models for computing relative depth from a single image.**\n",
        "\n",
        "<img src=\"https://pytorch.org/assets/images/midas_samples.png\" alt=\"alt\" width=\"50%\"/>\n",
        "\n",
        "\n",
        "### Model Description\n",
        "\n",
        "[MiDaS](https://arxiv.org/abs/1907.01341) computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using\n",
        "multi-objective optimization to ensure high quality on a wide range of inputs.\n",
        "\n",
        "### Dependencies\n",
        "\n",
        "MiDaS depends on [timm](https://github.com/rwightman/pytorch-image-models). Install with"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "shell"
          ],
          "id": ""
        },
        "id": "0YlPXo7ZbhMb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1347f0c-dff0-40ba-96fb-7db8c7612e1d"
      },
      "source": [
        "pip install timm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n",
            "\u001b[?25l\r\u001b[K     |▉                               | 10 kB 23.3 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20 kB 27.1 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40 kB 26.1 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |██████                          | 71 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 81 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 112 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 163 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 215 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 225 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 266 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 276 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 286 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 317 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 327 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 337 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 368 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 376 kB 8.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.10.0+cu102)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.4.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3hy8wa3bhMc"
      },
      "source": [
        "### Example Usage\n",
        "\n",
        "Download an image from the PyTorch homepage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v52j5fNbhMc"
      },
      "source": [
        "import cv2\n",
        "from IPython.display import Image, display\n",
        "import torch\n",
        "import urllib.request\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "filename ='/content/' + 'images.jpg'\n",
        "\n",
        "#url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
        "#urllib.request.urlretrieve(url, filename)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ql6QKbJbhMd"
      },
      "source": [
        "Load a model (see [https://github.com/intel-isl/MiDaS/#Accuracy](https://github.com/intel-isl/MiDaS/#Accuracy) for an overview)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9mJ_MZbbhMd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "947d38503d8b42b0bce66b5f009bb1e4",
            "f9cfb46e074e44cf87cc84e59c03b5c8",
            "86711289496646169611e33496d984be",
            "08332669b3624318acd84cf1e6e31269",
            "7001155c7eb6403d86288fbbd6524466",
            "0f3249c81aed41af965eede09697119c",
            "6c0b8e5014654f0f8b4ac1eeb0a79898",
            "29b943ee38a345dd8b7e5498c097d1da",
            "43bc410a74d64fc99425f01aab3dc551",
            "c4821fc1537c4fafad67ad9c6821b0f8",
            "5d901f7b7c3d4f3a84115f1d2b92812f"
          ]
        },
        "outputId": "3bc0caaf-4f52-4d4f-9ffe-5ef5759dd7dc"
      },
      "source": [
        "model_type = \"DPT_Large\"     # MiDaS v3 - Large     (highest accuracy, slowest inference speed)\n",
        "#model_type = \"DPT_Hybrid\"   # MiDaS v3 - Hybrid    (medium accuracy, medium inference speed)\n",
        "#model_type = \"MiDaS_small\"  # MiDaS v2.1 - Small   (lowest accuracy, highest inference speed)\n",
        "\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/intel-isl/MiDaS/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n",
            "Downloading: \"https://github.com/intel-isl/DPT/releases/download/1_0/dpt_large-midas-2f21e586.pt\" to /root/.cache/torch/hub/checkpoints/dpt_large-midas-2f21e586.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "947d38503d8b42b0bce66b5f009bb1e4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/1.28G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfPvvjZ4bhMd"
      },
      "source": [
        "Move model to GPU if available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuqUXK_zbhMd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6071ac89-54a5-4795-d33a-5ce827f53bcb"
      },
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "midas.to(device)\n",
        "midas.eval()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DPTDepthModel(\n",
              "  (pretrained): Module(\n",
              "    (model): VisionTransformer(\n",
              "      (patch_embed): PatchEmbed(\n",
              "        (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
              "        (norm): Identity()\n",
              "      )\n",
              "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "      (blocks): Sequential(\n",
              "        (0): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (pre_logits): Identity()\n",
              "      (head): Linear(in_features=1024, out_features=1000, bias=True)\n",
              "    )\n",
              "    (act_postprocess1): Sequential(\n",
              "      (0): ProjectReadout(\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "          (1): GELU()\n",
              "        )\n",
              "      )\n",
              "      (1): Transpose()\n",
              "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
              "      (3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(4, 4))\n",
              "    )\n",
              "    (act_postprocess2): Sequential(\n",
              "      (0): ProjectReadout(\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "          (1): GELU()\n",
              "        )\n",
              "      )\n",
              "      (1): Transpose()\n",
              "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
              "      (3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
              "    )\n",
              "    (act_postprocess3): Sequential(\n",
              "      (0): ProjectReadout(\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "          (1): GELU()\n",
              "        )\n",
              "      )\n",
              "      (1): Transpose()\n",
              "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
              "      (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (act_postprocess4): Sequential(\n",
              "      (0): ProjectReadout(\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "          (1): GELU()\n",
              "        )\n",
              "      )\n",
              "      (1): Transpose()\n",
              "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
              "      (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (scratch): Module(\n",
              "    (layer1_rn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (layer2_rn): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (layer3_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (layer4_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (refinenet1): FeatureFusionBlock_custom(\n",
              "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (resConfUnit1): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (resConfUnit2): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (refinenet2): FeatureFusionBlock_custom(\n",
              "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (resConfUnit1): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (resConfUnit2): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (refinenet3): FeatureFusionBlock_custom(\n",
              "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (resConfUnit1): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (resConfUnit2): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (refinenet4): FeatureFusionBlock_custom(\n",
              "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (resConfUnit1): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (resConfUnit2): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (output_conv): Sequential(\n",
              "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): Interpolate()\n",
              "      (2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Identity()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyeBrmVVbhMe"
      },
      "source": [
        "Load transforms to resize and normalize the image for large or small model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDl4eHNsbhMe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "593f8ccd-415f-42b2-ac71-3b399103cc8e"
      },
      "source": [
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
        "\n",
        "if model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n",
        "    transform = midas_transforms.dpt_transform\n",
        "else:\n",
        "    transform = midas_transforms.small_transform"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZcGjuRsbhMe"
      },
      "source": [
        "Load image and apply transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvVFeTK7bhMf"
      },
      "source": [
        "img = cv2.imread(filename)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "input_batch = transform(img).to(device)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xou4_fzebhMf"
      },
      "source": [
        "Predict and resize to original resolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeYhTz7BbhMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac29dfe5-42f3-4cd0-dcbf-cae12fbf2a2d"
      },
      "source": [
        "with torch.no_grad():\n",
        "    prediction = midas(input_batch)\n",
        "\n",
        "    prediction = torch.nn.functional.interpolate(\n",
        "        prediction.unsqueeze(1),\n",
        "        size=img.shape[:2],\n",
        "        mode=\"bicubic\",\n",
        "        align_corners=False,\n",
        "    ).squeeze()\n",
        "\n",
        "output = prediction.cpu().numpy()\n",
        "import os\n",
        "\n",
        "plt.imsave('/content/' + 'depth' + os.path.basename(os.path.normpath(filename)), output)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3613: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JMggcBXbhMf"
      },
      "source": [
        "Show result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxsp39uBbhMg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "4413bce4-ec58-4b7a-cae4-6f9608c15931"
      },
      "source": [
        "#plt.imshow(output)\n",
        "display(Image(filename))\n",
        "display(Image('/content/depth' + os.path.basename(os.path.normpath(filename))))\n",
        "# plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3CNVTMlbhMg"
      },
      "source": [
        "### References\n",
        "[Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-shot Cross-dataset Transfer](https://arxiv.org/abs/1907.01341)\n",
        "\n",
        "[Vision Transformers for Dense Prediction](https://arxiv.org/abs/2103.13413)\n",
        "\n",
        "Please cite our papers if you use our models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "bibtex"
          ],
          "id": ""
        },
        "id": "jDak8Yq6bhMg"
      },
      "source": [
        "@article{Ranftl2020,\n",
        "\tauthor    = {Ren\\'{e} Ranftl and Katrin Lasinger and David Hafner and Konrad Schindler and Vladlen Koltun},\n",
        "\ttitle     = {Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-shot Cross-dataset Transfer},\n",
        "\tjournal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},\n",
        "\tyear      = {2020},\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [
            "bibtex"
          ],
          "id": ""
        },
        "id": "1uhQIZKvbhMg"
      },
      "source": [
        "@article{Ranftl2021,\n",
        "\tauthor    = {Ren\\'{e} Ranftl and Alexey Bochkovskiy and Vladlen Koltun},\n",
        "\ttitle     = {Vision Transformers for Dense Prediction},\n",
        "\tjournal   = {ArXiv preprint},\n",
        "\tyear      = {2021},\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}